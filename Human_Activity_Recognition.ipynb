{
  "cells": [
    {
      "metadata": {
        "id": "pGwXjwxaOGDL"
      },
      "cell_type": "markdown",
      "source": [
        "## Time Series Classification\n",
        "\n",
        "#### Download the AReM data from: https://archive.ics.uci.edu/ml/datasets/Activity+Recognition+system+based+on+Multisensor+data+fusion+\\%28AReM\\%29 . The dataset contains 7 folders that represent seven types of activities. In each folder, there are multiple files each of which represents an instant of a human performing an activity. Each file containis 6 time series collected from activities of the same person. There are 88 instances in the dataset, each of which contains 6 time series and each time series has 480 consecutive values. \n",
        "#### Keep datasets 1 and 2 in folders bending1 and bending 2, as well as datasets 1, 2, and 3 in other folders as test data and other datasets as train data."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T04:11:01.073724Z",
          "start_time": "2018-07-03T04:11:01.060224Z"
        },
        "trusted": false,
        "id": "jtBO-cKMOGDP"
      },
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.linear_model import LogisticRegression, LassoCV,LogisticRegressionCV\n",
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
        "from sklearn.feature_selection import RFECV, RFE\n",
        "from sklearn.preprocessing import StandardScaler,label_binarize\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix,roc_curve, auc,roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T04:11:05.166347Z",
          "start_time": "2018-07-03T04:11:05.154364Z"
        },
        "trusted": false,
        "id": "fosHtbUpOGDW"
      },
      "cell_type": "code",
      "source": [
        "#variable declarations\n",
        "data_path = os.getcwd() + '/dataset'\n",
        "\n",
        "def create_header(names):\n",
        "    imp_list = []\n",
        "    for i in range(1, 7):\n",
        "        for label in names:\n",
        "            imp_list.append(label + str(i))\n",
        "    return imp_list\n",
        "\n",
        "\n",
        "col_headers = create_header(\n",
        "    ['min', 'max', 'mean', 'median', 'std_dev', '1st_quart', '3rd_quart'])\n",
        "col_headers.append('class')\n",
        "imp_headers = create_header(['median', 'std_dev', '1st_quart'])\n",
        "imp_headers.append('class')\n",
        "feature_cols = np.delete(col_headers, 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A9vYga6fOGDZ"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Splitting and Feature Extraction"
      ]
    },
    {
      "metadata": {
        "id": "1uU6NPmtOGDa"
      },
      "cell_type": "markdown",
      "source": [
        "##### - Different time domain features used in time series classification are: Minimum, Maximum, Standard Deviation, Mean, 1st Quartile, 3rd Quartile"
      ]
    },
    {
      "metadata": {
        "id": "Ync8K-WVOGDl"
      },
      "cell_type": "markdown",
      "source": [
        "##### - The three important time domain features selected are median, std deviation and 1st quartile (using feature selection method)"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T04:11:15.614349Z",
          "start_time": "2018-07-03T04:11:15.578833Z"
        },
        "trusted": true,
        "id": "nLJ_grHXOGDm"
      },
      "cell_type": "code",
      "source": [
        "#read data and split into test and train files\n",
        "def train_test_split(data_path):\n",
        "    train_files = []\n",
        "    test_files = []\n",
        "    exclude_binding_dataset = ['dataset1.csv', 'dataset2.csv']\n",
        "    exclude_dataset = ['dataset1.csv', 'dataset2.csv', 'dataset3.csv']\n",
        "    for act in os.listdir(data_path):\n",
        "        names = os.listdir(data_path + '/' + act)\n",
        "        if 'bending' in act:\n",
        "            train_files = train_files + [\n",
        "                act + '/' + f for f in names\n",
        "                if f not in exclude_binding_dataset\n",
        "            ]\n",
        "            test_files = test_files + [\n",
        "                act + '/' + s for s in exclude_binding_dataset\n",
        "            ]\n",
        "        else:\n",
        "            train_files = train_files + [\n",
        "                act + '/' + f for f in names if f not in exclude_dataset\n",
        "            ]\n",
        "            test_files = test_files + [act + '/' + s for s in exclude_dataset]\n",
        "    return train_files, test_files\n",
        "\n",
        "\n",
        "#get time domain featuers for each instance\n",
        "def get_features(file, split_time_series=None, multi_class = None):\n",
        "    instance_list = []\n",
        "    file = data_path + '/' + file\n",
        "    if 'bending' in file:\n",
        "        class_type = 1\n",
        "    else:\n",
        "        class_type = 0\n",
        "    df = pd.read_csv(file, header=4, usecols=[*range(1, 7)])\n",
        "    dflist = [df]\n",
        "    if split_time_series is not None:\n",
        "        dflist = np.array_split(df, split_time_series)\n",
        "    for df in dflist:\n",
        "        row = []\n",
        "        stat_df = df.agg(['min', 'max', 'mean', 'median', 'std'])\n",
        "        stat_df = stat_df.append(df.quantile(q=0.25))\n",
        "        stat_df = stat_df.append(df.quantile(q=0.75))\n",
        "        for col in [stat_df[f] for f in stat_df]:\n",
        "            for data in col:\n",
        "                row.append(data)\n",
        "        row.append(class_type)\n",
        "        instance_list.append(row)\n",
        "    return instance_list\n",
        "\n",
        "def get_instance_frame(file_list,split_size=None):\n",
        "    total_instance_frame = pd.DataFrame()\n",
        "    total_instance_list = []\n",
        "    for file in file_list:\n",
        "        instance_features = get_features(file,split_size)\n",
        "        total_instance_list = total_instance_list + instance_features\n",
        "\n",
        "    total_instance_frame = pd.DataFrame(total_instance_list, columns=col_headers)\n",
        "    return total_instance_frame\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T04:11:23.148054Z",
          "start_time": "2018-07-03T04:11:23.129556Z"
        },
        "trusted": false,
        "id": "jg0W8RgbOGDp"
      },
      "cell_type": "code",
      "source": [
        "train_files, test_files = train_test_split(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sjo5U5FQOGDq"
      },
      "cell_type": "markdown",
      "source": [
        "### Binary Classification Using Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "Mi__30nHOGDt"
      },
      "cell_type": "markdown",
      "source": [
        "#### (i) Assume that you want to use the training set to classify bending from other activities, i.e. you have a binary classification problem. Depict scatter plots of the features you specified in 1(c)iii extracted from time series 1, 2, and 6 of each instance, and use color to distinguish bending vs. other activities. "
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-02T22:33:46.997093Z",
          "start_time": "2018-07-02T22:32:44.706227Z"
        },
        "scrolled": true,
        "trusted": false,
        "id": "q7oEgt3QOGDt"
      },
      "cell_type": "code",
      "source": [
        "total_instance_frame = get_instance_frame(train_files + test_files, 1)\n",
        "total_selected_frame = total_instance_frame[imp_headers]\n",
        "scatter_plot = sns.pairplot(data=total_selected_frame, vars= ['median1','std_dev1','1st_quart1',\n",
        "                  'median2','std_dev2','1st_quart2','median6','std_dev6','1st_quart6'], kind='scatter', palette=\"Set2\",hue='class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "52l4I6alOGDv"
      },
      "cell_type": "markdown",
      "source": [
        "#### (ii) Break each time series in your training set into two (approximately) equal length time series. Now instead of 6 time series for each of the 88 instances, you have 12 time series for each instance. Repeat the experiment in 1(d)i. Do you see any considerable difference in the results with those of 1(d)i?"
      ]
    },
    {
      "metadata": {
        "id": "NHz5MiTdOGDw"
      },
      "cell_type": "markdown",
      "source": [
        "##### - we find no significant different between 2 scatter plots"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T05:19:12.638073Z",
          "start_time": "2018-07-03T05:18:44.639833Z"
        },
        "scrolled": true,
        "trusted": false,
        "id": "bheppxBJOGDx"
      },
      "cell_type": "code",
      "source": [
        "total_instance_frame = get_instance_frame(train_files + test_files, 2)\n",
        "total_selected_frame = total_instance_frame[imp_headers]\n",
        "scatter_plot = sns.pairplot(data=total_selected_frame, vars= ['median1','std_dev1','1st_quart1',\n",
        "                  'median2','std_dev2','1st_quart2','median6','std_dev6','1st_quart6'], kind='scatter', palette=\"Set2\",hue='class')\n",
        "plt.figure()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tkcqijvLOGDy"
      },
      "cell_type": "markdown",
      "source": [
        "#### (iii) Break each time series in your training set into l ∈ {1,2,...,20} time series of approximately equal length and use logistic regression 5 to solve the binary classification problem, using time-domain features. Calculate the p-values for your logistic regression parameters and refit a logistic regression model using your pruned set of features. 6 Alternatively, you can use backward selection using sklearn.feature selection or glm in R. Use 5-fold cross-validation to determine the best value of l. Explain what the right way and the wrong way are to perform cross-validation in this problem. 7 Obviously, use the right way! Also, you may encounter the problem of class imbalance, which may make some of your folds not having any instances of the rare class. In such a case, you can use stratified cross validation. Research what it means and use it if needed."
      ]
    },
    {
      "metadata": {
        "id": "5Hw-RsdXOGDz"
      },
      "cell_type": "markdown",
      "source": [
        "###### - The right way to perform cross validation is on both L and variable selection. To avoid problem of class balance, we have also used startified cross validation"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T04:09:09.331964Z",
          "start_time": "2018-07-03T04:01:38.107249Z"
        },
        "scrolled": true,
        "trusted": false,
        "id": "oCNKh_HNOGD0"
      },
      "cell_type": "code",
      "source": [
        "feature_cols = np.delete(col_headers, 42)\n",
        "best_cv_score = 0\n",
        "best_l = 0\n",
        "for l in range(1,10):\n",
        "    Y_train = train_instance_list = []\n",
        "    X_train = train_instance_frame = pd.DataFrame()\n",
        "    train_instance_frame = get_instance_frame(train_files, l)\n",
        "    \n",
        "    Y_train = train_instance_frame['class']\n",
        "    X_train = train_instance_frame.drop(['class'], axis=1)\n",
        "    logreg = LogisticRegression()    \n",
        "    for i in range(1,len(X_train.columns)):\n",
        "        rfe_res = RFE(estimator=logreg, n_features_to_select= i)\n",
        "        rfe_res.fit(X_train, Y_train)\n",
        "        cv_score = cross_val_score(rfe_res, X_train, Y_train, cv=5, scoring='accuracy')  \n",
        "        mean_score  =  np.mean(cv_score)\n",
        "        if mean_score > best_cv_score:\n",
        "            best_cv_score = mean_score\n",
        "            n_features = i   \n",
        "            best_l = l\n",
        "            best_features = feature_cols[rfe_res.support_]\n",
        "\n",
        "print(\"The best value of L for Logistic Regression is :\" , best_l )            \n",
        "print(\"Optimal cv score for Logistic Regression is :\" , best_cv_score)\n",
        "print(\"Optimal number of features for Logistic Regression is : \" , n_features)\n",
        "print(\"The Optimal features for Logistic Regression are : \", best_features)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NEKfxcRHOGD2"
      },
      "cell_type": "markdown",
      "source": [
        "#### (iv) Report the confusion matrix and show the ROC and AUC for your classifier on train data. Report the parameters of your logistic regression β i ’s as well as the p-values associated with them."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T04:09:46.139909Z",
          "start_time": "2018-07-03T04:09:42.905434Z"
        },
        "trusted": false,
        "id": "rbGsO2qoOGD2"
      },
      "cell_type": "code",
      "source": [
        "train_instance_frame = get_instance_frame(train_files, best_l)\n",
        "Y_train = train_instance_frame['class']\n",
        "X_train = train_instance_frame.drop(['class'], axis=1)\n",
        "X_train = X_train[best_features]\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, Y_train)\n",
        "Y_pred = logreg.predict(X_train)\n",
        "\n",
        "conf_mat = confusion_matrix(Y_train, Y_pred)\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(conf_mat, annot=True, cbar= False, ax = ax);\n",
        "plt.title('Train Confusion Matrix - Logistic Regression')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('True Value')\n",
        "plt.show()\n",
        "\n",
        "roc_auc = roc_auc_score(Y_train, Y_pred)\n",
        "fp_rate, tp_rate, thresholds = roc_curve(Y_train, Y_pred)\n",
        "plt.figure()\n",
        "plt.plot(fp_rate, tp_rate, label='Logistic Regression (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC - Logistic Regression')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T04:10:34.193858Z",
          "start_time": "2018-07-03T04:10:34.100878Z"
        },
        "trusted": false,
        "id": "MXSwTBU3OGD4"
      },
      "cell_type": "code",
      "source": [
        "logit_model=sm.Logit(Y_train,X_train)\n",
        "result=logit_model.fit(maxiter = 21)\n",
        "result.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eVL5LxybOGD5"
      },
      "cell_type": "markdown",
      "source": [
        "##### - In the above logit Regression output, coef_ column gives us Beta parameter values and p-values are given by P>|z| column"
      ]
    },
    {
      "metadata": {
        "id": "O988zJD3OGD6"
      },
      "cell_type": "markdown",
      "source": [
        "#### (v) Test the classifier on the test set. Remember to break the time series in your test set into the same number of time series into which you broke your training set. Remember that the classifier has to be tested using the features extracted from the test set. Compare the accuracy on the test set with the cross-validation accuracy you obtained previously."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T04:09:52.944498Z",
          "start_time": "2018-07-03T04:09:51.645013Z"
        },
        "scrolled": true,
        "trusted": false,
        "id": "5fiAdMk4OGD7"
      },
      "cell_type": "code",
      "source": [
        "test_instance_frame = get_instance_frame(test_files, best_l)\n",
        "Y_test = test_instance_frame['class']\n",
        "X_test = test_instance_frame.drop(['class'], axis=1)\n",
        "X_test = X_test[best_features]\n",
        "\n",
        "Y_pred = logreg.predict(X_test)\n",
        "print(\"The Test Accuracy is : %d\" %metrics.accuracy_score(Y_test, Y_pred) )            \n",
        "\n",
        "conf_mat = confusion_matrix(Y_test, Y_pred)\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(conf_mat, annot=True, cbar= False, ax = ax);\n",
        "plt.title('Test Confusion Matrix - Logistic Regression')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('True Value')\n",
        "plt.show()\n",
        "\n",
        "roc_auc = roc_auc_score(Y_test, Y_pred)\n",
        "fp_rate, tp_rate, thresholds = roc_curve(Y_test, Y_pred)\n",
        "plt.figure()\n",
        "plt.plot(fp_rate, tp_rate, label='Logistic Regression (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC - Logitic Regression')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3s1y6rrsOGD8"
      },
      "cell_type": "markdown",
      "source": [
        "#### (vi) Do your classes seem to be well-separated to cause instability in calculating logistic regression parameters?\n",
        "##### - Yes, from the warning of statsmodel code we find that classes are well-separated thereby resulting in instability in calculating beta and p-values"
      ]
    },
    {
      "metadata": {
        "id": "yctceA_xOGD8"
      },
      "cell_type": "markdown",
      "source": [
        "#### (vii) From the confusion matrices you obtained, do you see imbalanced classes? If yes, build a logistic regression model based on case-control sampling and adjust its parameters. Report the confusion matrix, ROC, and AUC of the model."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T03:52:00.888465Z",
          "start_time": "2018-07-03T03:47:30.023439Z"
        },
        "trusted": false,
        "id": "ArQZ8A0WOGD9"
      },
      "cell_type": "code",
      "source": [
        "feature_cols = np.delete(col_headers, 42)\n",
        "best_cv_score = 0\n",
        "best_l = 0\n",
        "for l in range(1,21):\n",
        "    Y_train = train_instance_list = []\n",
        "    X_train = train_instance_frame = pd.DataFrame()\n",
        "    train_instance_frame = get_instance_frame(train_files, l)\n",
        "    \n",
        "    Y_train = train_instance_frame['class']\n",
        "    X_train = train_instance_frame.drop(['class'], axis=1)\n",
        "    \n",
        "    rus = RandomUnderSampler()\n",
        "    X_sampled_train, y_sampled_train = rus.fit_sample(X_train, Y_train)\n",
        "    \n",
        "    logreg = LogisticRegression()    \n",
        "    for i in range(1,len(X_train.columns)):\n",
        "        rfe_res = RFE(estimator=logreg, n_features_to_select= i)\n",
        "        rfe_res.fit(X_sampled_train, y_sampled_train)\n",
        "        cv_score = cross_val_score(rfe_res, X_sampled_train, y_sampled_train, cv=5, scoring='accuracy')  \n",
        "        mean_score  =  np.mean(cv_score)\n",
        "        if mean_score > best_cv_score:\n",
        "            best_cv_score = mean_score\n",
        "            n_features = i   \n",
        "            best_l = l\n",
        "            best_features = feature_cols[rfe_res.support_]\n",
        "\n",
        "print(\"The best value of L for case control sampling is :\" , best_l )            \n",
        "print(\"Optimal CV score for case control sampling is :\" , best_cv_score)\n",
        "print(\"Optimal number of features for case control sampling : \" , n_features)\n",
        "print(\"The Optimal features for for case control sampling are : \", best_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T03:54:34.619912Z",
          "start_time": "2018-07-03T03:54:31.407436Z"
        },
        "trusted": false,
        "id": "vVyjWBOeOGD-"
      },
      "cell_type": "code",
      "source": [
        "train_files, test_files = train_test_split(data_path)\n",
        "\n",
        "train_instance_frame = get_instance_frame(train_files, best_l)\n",
        "Y_train = train_instance_frame['class']\n",
        "X_train = train_instance_frame.drop(['class'], axis=1)\n",
        "X_train = X_train[best_features]\n",
        "\n",
        "X_sampled_train, y_sampled_train =  RandomUnderSampler().fit_sample(X_train, Y_train)\n",
        "    \n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_sampled_train, y_sampled_train)\n",
        "Y_pred = logreg.predict(X_sampled_train)\n",
        "\n",
        "conf_mat = confusion_matrix(y_sampled_train, Y_pred)\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(conf_mat, annot=True, cbar= False, ax = ax);\n",
        "plt.title('Train Confusion Matrix - Case Control Sampling ')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('True Value')\n",
        "plt.show()\n",
        "\n",
        "roc_auc = roc_auc_score(y_sampled_train, Y_pred)\n",
        "fpr, tpr, thresholds = roc_curve(y_sampled_train, Y_pred)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Case Control Sampling (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T03:57:08.559328Z",
          "start_time": "2018-07-03T03:57:07.329328Z"
        },
        "trusted": false,
        "id": "ZGVjfRFmOGD_"
      },
      "cell_type": "code",
      "source": [
        "train_files, test_files = train_test_split(data_path)\n",
        "\n",
        "test_instance_frame = get_instance_frame(test_files, best_l)\n",
        "Y_test = test_instance_frame['class']\n",
        "X_test = test_instance_frame.drop(['class'], axis=1)\n",
        "X_test = X_test[best_features]\n",
        "\n",
        "X_sampled_test, y_sampled_test =  RandomUnderSampler().fit_sample(X_test, Y_test)\n",
        "\n",
        "Y_pred = logreg.predict(X_sampled_test)\n",
        "\n",
        "conf_mat = confusion_matrix(y_sampled_test, Y_pred)\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(conf_mat, annot=True, cbar= False, ax = ax);\n",
        "plt.title('Test Confusion Matrix - Case Control Sampling')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('True Value')\n",
        "plt.show()\n",
        "\n",
        "roc_auc = roc_auc_score(y_sampled_test, Y_pred)\n",
        "fpr, tpr, thresholds = roc_curve(y_sampled_test, Y_pred)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Case Control Sampling (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q4ZXOi45OGEA"
      },
      "cell_type": "markdown",
      "source": [
        "### Binary Classification Using L 1 -penalized logistic regression"
      ]
    },
    {
      "metadata": {
        "id": "g2X523NjOGEB"
      },
      "cell_type": "markdown",
      "source": [
        "#### (i) Repeat 1(d)iii using L 1 -penalized logistic regression, 8 i.e. instead of using p-values for variable selection, use L 1 regularization. Note that in this problem,you have to cross-validate for both l, the number of time series into which you break each of your instances, and λ, the weight of L 1 penalty in your logistic regression objective function (or C, the budget). Packages usually perform cross-validation for λ automatically. "
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T03:29:19.988429Z",
          "start_time": "2018-07-03T03:14:37.110749Z"
        },
        "scrolled": true,
        "trusted": false,
        "id": "Oijoz6c3OGEC"
      },
      "cell_type": "code",
      "source": [
        "train_files, test_files = train_test_split(data_path)\n",
        "\n",
        "best_l = 0\n",
        "best_cv_score = 0 \n",
        "for l in range(1,21):\n",
        "    Y_train = []\n",
        "    X_train = pd.DataFrame()\n",
        "    train_instance_frame = get_instance_frame(train_files, l)\n",
        "    Y_train = train_instance_frame['class']\n",
        "    X_train = train_instance_frame.drop(['class'], axis=1)\n",
        "    \n",
        "    #normalization\n",
        "    scalar = StandardScaler()\n",
        "    X_train  = scalar.fit_transform(X_train)\n",
        "    \n",
        "    lasso = LogisticRegressionCV(penalty = 'l1',cv=StratifiedKFold(5),solver='liblinear')\n",
        "    lasso = lasso.fit(X_train, Y_train)\n",
        "    cv_score = cross_val_score(lasso, X_train, Y_train, cv=StratifiedKFold(5), scoring='accuracy')  \n",
        "    mean_score  =  np.mean(cv_score)\n",
        "    if mean_score > best_cv_score:\n",
        "        best_cv_score = mean_score\n",
        "        best_l = l\n",
        "        best_C = lasso.C_[0]\n",
        "\n",
        "print(\"The best L-value for binary Log Reg L1 Penalty is : \", best_l )\n",
        "print(\"The best C-value for binary Log Reg L1 Penalty : \" ,best_C )\n",
        "print(\"Optimal CV score for binary Log Reg L1 Penalty: \" ,  best_cv_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T04:39:54.372029Z",
          "start_time": "2018-07-03T04:39:50.855091Z"
        },
        "scrolled": true,
        "trusted": false,
        "id": "fGQ-EGo1OGED"
      },
      "cell_type": "code",
      "source": [
        "#perform binary L 1 -penalized logistic regression on train data using best L value and c-value obtained above\n",
        "train_files, test_files = train_test_split(data_path)\n",
        "\n",
        "train_instance_frame = get_instance_frame(train_files, best_l)\n",
        "Y_train = train_instance_frame['class']\n",
        "X_train = train_instance_frame.drop(['class'], axis=1)\n",
        "\n",
        "#normalization\n",
        "scalar = StandardScaler()\n",
        "X_train  = scalar.fit_transform(X_train)\n",
        "\n",
        "lasso = LogisticRegression(penalty = 'l1', C = best_C, solver='liblinear')\n",
        "lasso = lasso.fit(X_train, Y_train)\n",
        "Y_pred = lasso.predict(X_train)\n",
        "conf_matrix = confusion_matrix(Y_train, Y_pred)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(conf_matrix, annot=True, cbar= False, ax = ax);\n",
        "plt.title('Train Confusion Matrix - Binary Log Reg L1 Penalty')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('True Value')\n",
        "plt.show()\n",
        "\n",
        "roc_auc = roc_auc_score(Y_train, Y_pred)\n",
        "fpr, tpr, thresholds = roc_curve(Y_train, Y_pred)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Log Reg L1 Penalty (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC - Binary Log Reg L1 Penalty')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T04:40:23.317314Z",
          "start_time": "2018-07-03T04:40:22.056334Z"
        },
        "trusted": false,
        "id": "EQqrNuAgOGEE"
      },
      "cell_type": "code",
      "source": [
        "#perform binary L 1 -penalized logistic regression on test data using best L value and c-value obtained above\n",
        "train_files, test_files = train_test_split(data_path)\n",
        "\n",
        "test_instance_frame = get_instance_frame(test_files, best_l)\n",
        "Y_test = test_instance_frame['class']\n",
        "X_test = test_instance_frame.drop(['class'], axis=1)\n",
        "\n",
        "scalar = StandardScaler()\n",
        "X_test  = scalar.fit_transform(X_test)\n",
        "\n",
        "Y_pred = lasso.predict(X_test)\n",
        "\n",
        "accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
        "print(\"Test Error rate for Binary Log Reg L1 penalty is : \", 1-test_error )\n",
        "\n",
        "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(conf_matrix, annot=True, cbar= False, ax = ax);\n",
        "plt.title('Test Confusion Matrix - Binary Log Reg L1 Penalty')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('True Value')\n",
        "plt.show()\n",
        "\n",
        "roc_auc = roc_auc_score(Y_test, Y_pred)\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, Y_pred)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Log Reg L1 Penalty (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC - Binary Log Reg L1 Penalty')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OiMZE8zkOGEF"
      },
      "cell_type": "markdown",
      "source": [
        "#### (iii)  Compare the L 1 -penalized with variable selection using p-values. Which one performs better? Which one is easier to implement?\n",
        "##### - Logistic Regression with variable selection will perform better as it has higher CV than l1 penalized. However, l1 penalized regression is easier to implement as it avoids variable selection loop thereby reducing computational load"
      ]
    },
    {
      "metadata": {
        "id": "wWbI0PlqOGEG"
      },
      "cell_type": "markdown",
      "source": [
        "### Multi-class Classification"
      ]
    },
    {
      "metadata": {
        "id": "nt9pwVxMOGEG"
      },
      "cell_type": "markdown",
      "source": [
        "#### (i). Find the best l in the same way as you found it in 1(e)i to build an L 1 -penalized multinomial regression model to classify all activities in your training set. Report your test error. Research how confusion matrices and ROC curves are defined for multiclass classification and show them for this problem if possible."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T03:01:37.236186Z",
          "start_time": "2018-07-03T03:01:37.192188Z"
        },
        "trusted": false,
        "id": "HxJFOfzXOGEH"
      },
      "cell_type": "code",
      "source": [
        "#get time domain featuers for each instance\n",
        "multi_class_labels = ['bending1', 'bending2','cycling','lying', 'sitting', 'standing', 'walking']\n",
        "\n",
        "def get_features_multi_class(file, split_time_series=None):\n",
        "    instance_list = []\n",
        "    class_type = file.split('/')[0]\n",
        "    file = data_path + '/' + file\n",
        "    df = pd.read_csv(file, header=4, usecols=[*range(1, 7)])\n",
        "    dflist = [df]\n",
        "    if split_time_series is not None:\n",
        "        dflist = np.array_split(df, split_time_series)\n",
        "    for df in dflist:\n",
        "        row = []\n",
        "        stat_df = df.agg(['min', 'max', 'mean', 'median', 'std'])\n",
        "        stat_df = stat_df.append(df.quantile(q=0.25))\n",
        "        stat_df = stat_df.append(df.quantile(q=0.75))\n",
        "        for col in [stat_df[f] for f in stat_df]:\n",
        "            for data in col:\n",
        "                row.append(data)\n",
        "        row.append(class_type)\n",
        "        instance_list.append(row)\n",
        "    return instance_list\n",
        "\n",
        "\n",
        "def get_multi_class_instance_frame(file_list, split_size=None):\n",
        "    total_instance_frame = pd.DataFrame()\n",
        "    total_instance_list = []\n",
        "    for file in file_list:\n",
        "        instance_features = get_features_multi_class(file,split_size)\n",
        "        total_instance_list = total_instance_list + instance_features\n",
        "\n",
        "    total_instance_frame = pd.DataFrame(\n",
        "        total_instance_list, columns=col_headers)\n",
        "    return total_instance_frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T03:01:40.413647Z",
          "start_time": "2018-07-03T03:01:40.379174Z"
        },
        "trusted": false,
        "id": "z4dPmY7AOGEI"
      },
      "cell_type": "code",
      "source": [
        "def multiclass_roc(y_true, y_pred):\n",
        "    ''' \n",
        "        This function plots ROC curve with AUC for\n",
        "        multiclass classification\n",
        "    '''\n",
        "    multi_class_labels = ['bending1', 'bending2','cycling', 'lying','sitting', 'standing', 'walking']\n",
        "    lw=2\n",
        "    fpr = tpr = roc_auc = dict()\n",
        "    colors = ['purple','brown','blue','green','yellow','orange','red']\n",
        "    for i in range(0,7):\n",
        "        fpr, tpr, _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, color=colors[i],\n",
        "             lw=lw, label=f'ROC curve for {multi_class_labels[i]} (area = %0.2f)' %roc_auc)\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T02:29:48.994124Z",
          "start_time": "2018-07-03T02:16:16.179044Z"
        },
        "trusted": false,
        "id": "1YUiBzWOOGEJ"
      },
      "cell_type": "code",
      "source": [
        "#perform L1-penalized multiclass logistic regression to find best L value\n",
        "\n",
        "train_files, test_files = train_test_split(data_path)\n",
        "\n",
        "best_l = 0\n",
        "best_cv_score = 0\n",
        "for l in range(1, 21):\n",
        "    Y_train = []\n",
        "    X_train = pd.DataFrame()\n",
        "    train_instance_frame = get_multi_class_instance_frame(train_files, l)\n",
        "    Y_train = train_instance_frame['class']\n",
        "    X_train = train_instance_frame.drop(['class'], axis=1)\n",
        "\n",
        "    #normalization\n",
        "    scalar = StandardScaler()\n",
        "    X_test  = scalar.fit_transform(X_test)\n",
        "\n",
        "    multi_lasso = LogisticRegressionCV(\n",
        "        penalty='l1',\n",
        "        multi_class='multinomial',\n",
        "        cv=3,\n",
        "        solver='saga')\n",
        "    multi_lasso = multi_lasso.fit(X_train, Y_train)\n",
        "    cv_score = cross_val_score(\n",
        "        multi_lasso, X_train, Y_train, cv=3, scoring='accuracy')\n",
        "    mean_score = np.mean(cv_score)\n",
        "    if mean_score > best_cv_score:\n",
        "        best_cv_score = mean_score\n",
        "        best_l = l\n",
        "        best_C = multi_lasso.C_[0]\n",
        "        \n",
        "print(\"The best L-value Multiclass Log Reg L1 penalty is : \", best_l )\n",
        "print(\"The best C-value Multiclass Log Reg L1 penalty is : \" ,best_C )\n",
        "print(\"Optimal CV score Multiclass Log Reg L1 penalty is: \" ,  best_cv_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T04:49:20.007521Z",
          "start_time": "2018-07-03T04:49:20.000521Z"
        },
        "id": "_X5ETRCZOGEL"
      },
      "cell_type": "markdown",
      "source": [
        "###### Note: We have used cv = 3 to avoid  number of samples warning resulting from limited samples in bending1 and bending2 dataset"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T03:03:23.833384Z",
          "start_time": "2018-07-03T03:03:12.172033Z"
        },
        "trusted": false,
        "id": "zAW-Qa2zOGEM"
      },
      "cell_type": "code",
      "source": [
        "#perform L1-penalized multiclass logistic regression on train data using best L value and C value obtained from above\n",
        "\n",
        "train_files, test_files = train_test_split(data_path)\n",
        "\n",
        "train_instance_frame = get_multi_class_instance_frame(train_files, best_l)\n",
        "Y_train = train_instance_frame['class']\n",
        "X_train = train_instance_frame.drop(['class'], axis=1)\n",
        "\n",
        "#normalization\n",
        "scalar = StandardScaler()\n",
        "X_train  = scalar.fit_transform(X_train)\n",
        "multi_lasso = LogisticRegression(penalty = 'l1', C = best_C, multi_class='multinomial', solver='saga')\n",
        "multi_lasso = multi_lasso.fit(X_train, Y_train)\n",
        "Y_pred = multi_lasso.predict(X_train)\n",
        "\n",
        "conf_matrix = confusion_matrix(Y_train, Y_pred)\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(conf_matrix, annot=True, cbar= False, ax = ax);\n",
        "plt.title('Train Confusion Matrix - Multiclass Log Reg L1 penalty')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('True Value')\n",
        "plt.show()\n",
        "\n",
        "Y_train = label_binarize(Y_train, classes= multi_class_labels)\n",
        "Y_pred = label_binarize(Y_pred, classes= multi_class_labels)\n",
        "multiclass_roc(Y_train, Y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T03:04:01.163441Z",
          "start_time": "2018-07-03T03:03:56.363502Z"
        },
        "trusted": false,
        "id": "Haj0wGbOOGEN"
      },
      "cell_type": "code",
      "source": [
        "#perform L1-penalized multiclass logistic regression (L1 penalty)on test data using best L value\n",
        "\n",
        "test_instance_frame = get_multi_class_instance_frame(test_files, best_l)\n",
        "Y_test = test_instance_frame['class']\n",
        "X_test = test_instance_frame.drop(['class'], axis=1)\n",
        "\n",
        "#normalization\n",
        "scalar = StandardScaler()\n",
        "X_test  = scalar.fit_transform(X_test)\n",
        "Y_pred = multi_lasso.predict(X_test)\n",
        "\n",
        "accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
        "print(\"Test Error rate for multi-class Log Reg L1 penalty is : \", 1-test_error )\n",
        "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(conf_matrix, annot=True, cbar= False, ax = ax);\n",
        "plt.title('Test Confusion Matrix - Multiclass Log Reg L1 penalty')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('True Value')\n",
        "plt.show()\n",
        "\n",
        "Y_test = label_binarize(Y_test, classes= multi_class_labels)\n",
        "Y_pred = label_binarize(Y_pred, classes= multi_class_labels)\n",
        "multiclass_roc(Y_test, Y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UuYYgsjWOGEO"
      },
      "cell_type": "markdown",
      "source": [
        "#### (ii) Repeat 1(f)i using a Naive Bayes’ classifier. Use both Gaussian and Multi-nomial priors and compare the results."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T02:34:54.888120Z",
          "start_time": "2018-07-03T02:31:49.985491Z"
        },
        "scrolled": true,
        "trusted": false,
        "id": "dY45qc7dOGEP"
      },
      "cell_type": "code",
      "source": [
        "#perform multi-class Naive Bayes(Gaussian Prior) to find best L\n",
        "train_files, test_files = train_test_split(data_path)\n",
        "\n",
        "best_l = 0\n",
        "best_cv_score = 0\n",
        "for l in range(1, 21):\n",
        "    train_instance_frame = get_multi_class_instance_frame(train_files, l)\n",
        "    Y_train = train_instance_frame['class']\n",
        "    X_train = train_instance_frame.drop(['class'], axis=1)\n",
        "    nbgaussian = GaussianNB()\n",
        "    nbgaussian = nbgaussian.fit(X_train, Y_train)\n",
        "    cv_score = cross_val_score(\n",
        "        nbgaussian, X_train, Y_train, cv=3, scoring='accuracy')\n",
        "    mean_score = np.mean(cv_score)\n",
        "    if mean_score > best_cv_score:\n",
        "        best_cv_score = mean_score\n",
        "        best_l = l\n",
        "\n",
        "print(\"The best L-value for multiclass naive bayes (Gaussian Prior) is : \", best_l)\n",
        "print(\"Optimal CV score for multiclass naive bayes (Gaussian Prior) is: \", best_cv_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T03:04:52.417951Z",
          "start_time": "2018-07-03T03:04:41.418091Z"
        },
        "trusted": false,
        "id": "2rI8UmX7OGEQ"
      },
      "cell_type": "code",
      "source": [
        "#perform multiclass naive bayes (Gaussian Prior) on train data using best L value obtained from above\n",
        "train_files, test_files = train_test_split(data_path)\n",
        "\n",
        "train_instance_frame = get_multi_class_instance_frame(train_files, best_l)\n",
        "Y_train = train_instance_frame['class']\n",
        "X_train = train_instance_frame.drop(['class'], axis=1)\n",
        "\n",
        "nbgaussian = GaussianNB()\n",
        "nbgaussian = nbgaussian.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = nbgaussian.predict(X_train)\n",
        "conf_matrix = confusion_matrix(Y_train, Y_pred)\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(conf_matrix, annot=True, cbar= False, ax = ax);\n",
        "plt.title('Train Confusion Matrix - Multiclass naive bayes (Gaussian Prior)')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('True Value')\n",
        "plt.show()\n",
        "\n",
        "Y_train = label_binarize(Y_train, classes= multi_class_labels)\n",
        "Y_pred = label_binarize(Y_pred, classes= multi_class_labels)\n",
        "multiclass_roc(Y_train, Y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T03:06:34.522353Z",
          "start_time": "2018-07-03T03:06:29.313922Z"
        },
        "trusted": false,
        "id": "MtWyIS7XOGER"
      },
      "cell_type": "code",
      "source": [
        "train_files, test_files = train_test_split(data_path)\n",
        "\n",
        "#perform multiclass naive bayes (Gaussian Prior) on test data using best L value\n",
        "\n",
        "test_instance_frame = get_multi_class_instance_frame(test_files, best_l)\n",
        "Y_test = test_instance_frame['class']\n",
        "X_test = test_instance_frame.drop(['class'], axis=1)\n",
        "\n",
        "Y_pred = nbgaussian.predict(X_test)\n",
        "\n",
        "accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
        "print(\"Test Error rate for multiclass naive bayes(Gaussian Prior) is : \", 1-accuracy )\n",
        "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(conf_matrix, annot=True, cbar= False, ax = ax);\n",
        "plt.title('Test Confusion Matrix - Multiclass naive bayes (Gaussian Prior)')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('True Value')\n",
        "plt.show()\n",
        "\n",
        "Y_test = label_binarize(Y_test, classes= multi_class_labels)\n",
        "Y_pred = label_binarize(Y_pred, classes= multi_class_labels)\n",
        "multiclass_roc(Y_test, Y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T02:39:37.535195Z",
          "start_time": "2018-07-03T02:36:32.054075Z"
        },
        "trusted": false,
        "id": "zPSybkD-OGES"
      },
      "cell_type": "code",
      "source": [
        "train_files, test_files = train_test_split(data_path)\n",
        "\n",
        "#perfor multi-class Naive Bayes(Multinomial Prior) to find best L\n",
        "best_l = 0\n",
        "best_cv_score = 0 \n",
        "for l in range(1,21):\n",
        "    train_instance_frame = get_multi_class_instance_frame(train_files, l)\n",
        "    Y_train = train_instance_frame['class']\n",
        "    X_train = train_instance_frame.drop(['class'], axis=1)\n",
        "    nbmultinomial = MultinomialNB()\n",
        "    nbmultinomial = nbmultinomial.fit(X_train, Y_train)\n",
        "    cv_score = cross_val_score(nbmultinomial, X_train, Y_train, cv = 3, scoring='accuracy')  \n",
        "    mean_score  =  np.mean(cv_score)\n",
        "    if mean_score > best_cv_score:\n",
        "        best_cv_score = mean_score\n",
        "        best_l = l\n",
        "\n",
        "print(\"The best L-value for multiclass naive bayes (Multinomial Prior) is : \", best_l )\n",
        "print(\"Optimal CV score for multiclass naive bayes (Multinomial Prior) is: \" ,  best_cv_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T03:07:54.348382Z",
          "start_time": "2018-07-03T03:07:47.026475Z"
        },
        "trusted": false,
        "id": "gFCad_QPOGET"
      },
      "cell_type": "code",
      "source": [
        "#perform multi-class Naive Bayes(Multinomial Prior) on train data using best L value\n",
        "train_files, test_files = train_test_split(data_path)\n",
        "best_l = 1\n",
        "train_instance_frame = get_multi_class_instance_frame(train_files, best_l)\n",
        "Y_train = train_instance_frame['class']\n",
        "X_train = train_instance_frame.drop(['class'], axis=1)\n",
        "\n",
        "nbmultinomial = MultinomialNB()\n",
        "nbmultinomial = nbmultinomial.fit(X_train, Y_train)\n",
        "Y_pred = nbmultinomial.predict(X_train)\n",
        "\n",
        "conf_matrix = confusion_matrix(Y_train, Y_pred)\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(conf_matrix, annot=True, cbar= False, ax = ax);\n",
        "plt.title('Train Confusion Matrix - Multiclass naive bayes (Multinomial Prior)')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('True Value')\n",
        "plt.show()\n",
        "\n",
        "Y_train = label_binarize(Y_train, classes= multi_class_labels)\n",
        "Y_pred = label_binarize(Y_pred, classes= multi_class_labels)\n",
        "multiclass_roc(Y_train, Y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-07-03T03:08:28.409018Z",
          "start_time": "2018-07-03T03:08:24.831064Z"
        },
        "trusted": false,
        "id": "e9B0CrzVOGEU"
      },
      "cell_type": "code",
      "source": [
        "#perform multi-class Naive Bayes(Multinomial Prior) on test data using best L value\n",
        "\n",
        "train_files, test_files = train_test_split(data_path)\n",
        "test_instance_frame = get_multi_class_instance_frame(test_files, best_l)\n",
        "Y_test = test_instance_frame['class']\n",
        "X_test = test_instance_frame.drop(['class'], axis=1)\n",
        "\n",
        "Y_pred = nbmultinomial.predict(X_test)\n",
        "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
        "\n",
        "accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
        "print(\"Test Error rate for multiclass naive bayes(Multinomial Prior) is : \", 1-accuracy )\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(conf_matrix, annot=True, cbar= False, ax = ax);\n",
        "plt.title('Test Confusion Matrix - Multiclass naive bayes (Multinomial Prior)')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('True Value')\n",
        "plt.show()\n",
        "\n",
        "Y_test = label_binarize(Y_test, classes= multi_class_labels)\n",
        "Y_pred = label_binarize(Y_pred, classes= multi_class_labels)\n",
        "multiclass_roc(Y_test, Y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8sRUqhFHOGEW"
      },
      "cell_type": "markdown",
      "source": [
        "##### - on comparing Gaussian and Multinomial Priors, we find that Naive Bayes with Gaussian prior has better cross validation accuracy as well as test error rate"
      ]
    },
    {
      "metadata": {
        "id": "i3IpQOuLOGEY"
      },
      "cell_type": "markdown",
      "source": [
        "#### (iii) Which method is better for multi-class classification in this problem?\n",
        "\n",
        " ##### - Naive Bayes with Gaussian Prior is better as it gives highest cross validation accuracy"
      ]
    },
    {
      "metadata": {
        "trusted": false,
        "id": "JPI0WotDOGEY"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "oldHeight": 539,
      "position": {
        "height": "40px",
        "left": "575px",
        "right": "234px",
        "top": "1px",
        "width": "557px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "varInspector_section_display": "none",
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}